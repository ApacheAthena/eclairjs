<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: sql/Dataset.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: sql/Dataset.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/*
 * Copyright 2016 IBM Corp.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

var Utils = require('../utils.js');

/**
 * @classdesc
 * A Dataset is a strongly typed collection of domain-specific objects that can be transformed
 * in parallel using functional or relational operations. Each Dataset also has an untyped view
 * called a [[Dataset]], which is a Dataset of {@link Row}.
 *
 * Operations available on Datasets are divided into transformations and actions. Transformations
 * are the ones that produce new Datasets, and actions are the ones that trigger computation and
 * return results. Example transformations include map, filter, select, and aggregate (`groupBy`).
 * Example actions count, show, or writing data out to file systems.
 *
 * Datasets are "lazy", i.e. computations are only triggered when an action is invoked. Internally,
 * a Dataset represents a logical plan that describes the computation required to produce the data.
 * When an action is invoked, Spark's query optimizer optimizes the logical plan and generates a
 * physical plan for efficient execution in a parallel and distributed manner. To explore the
 * logical plan as well as optimized physical plan, use the `explain` function.
 *
 * To efficiently support domain-specific objects, an {@link Encoder} is required. The encoder maps
 * the domain specific type `T` to Spark's internal type system. For example, given a class `Person`
 * with two fields, `name` (string) and `age` (int), an encoder is used to tell Spark to generate
 * code at runtime to serialize the `Person` object into a binary structure. This binary structure
 * often has much lower memory footprint as well as are optimized for efficiency in data processing
 * (e.g. in a columnar format). To understand the internal binary representation for data, use the
 * `schema` function.
 *
 * There are typically two ways to create a Dataset. The most common way is by pointing Spark
 * to some files on storage systems, using the `read` function available on a `SparkSession`.
 * @example
 *   val people = spark.read.parquet("...").as[Person]  // Scala
 *   Dataset&lt;Person> people = spark.read().parquet("...").as(Encoders.bean(Person.class)); // Java
 *
 *
 * Datasets can also be created through transformations available on existing Datasets. For example,
 * the following creates a new Dataset by applying a filter on the existing one:
 * @example
 *   val names = people.map(_.name)  // in Scala; names is a Dataset[String]
 *   Dataset&lt;String> names = people.map((Person p) -> p.name, Encoders.STRING)); // in Java 8
 *
 *
 * Dataset operations can also be untyped, through various domain-specific-language (DSL)
 * functions defined in: Dataset (this class), [[Column]], and {@link functions}. These operations
 * are very similar to the operations available in the data frame abstraction in R or Python.
 *
 * To select a column from the Dataset, use `apply` method in Scala and `col` in Java.
 * @example
 *   val ageCol = people("age")  // in Scala
 *   Column ageCol = people.col("age"); // in Java
 *
 *
 * Note that the {@link Column} type can also be manipulated through its various functions.
 * @example
 *   // The following creates a new column that increases everybody's age by 10.
 *   people("age") + 10  // in Scala
 *   people.col("age").plus(10);  // in Java
 *
 *
 * A more concrete example in Scala:
 * @example
 *   // To create Dataset[Row] using SparkSession
 *   val people = spark.read.parquet("...")
 *   val department = spark.read.parquet("...")
 *
 *   people.filter("age > 30")
 *     .join(department, people("deptId") === department("id"))
 *     .groupBy(department("name"), "gender")
 *     .agg(avg(people("salary")), max(people("age")))
 *
 *
 * and in Java:
 * @example
 *   // To create Dataset&lt;Row> using SparkSession
 *   Dataset&lt;Row> people = spark.read().parquet("...");
 *   Dataset&lt;Row> department = spark.read().parquet("...");
 *
 *   people.filter("age".gt(30))
 *     .join(department, people.col("deptId").equalTo(department("id")))
 *     .groupBy(department.col("name"), "gender")
 *     .agg(avg(people.col("salary")), max(people.col("age")));
 *
 *
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @class
 * @memberof module:eclairjs/sql
 */

/**
 * @param {module:eclairjs/sql.SQLContext} sqlContext
 * @param {module:eclairjs/sql/catalyst/plans/logical.LogicalPlan} logicalPlan
 * @param {module:eclairjs/sql.Encoder} encoder
 * @constructor
 */

function _resolveRows(result, resolve, reject) {
  try {
    var res = JSON.parse(result);

    var RowFactory = require('./RowFactory')(this.kernelP);

    var returnResult = null;

    if (Array.isArray(res)) {
      returnResult = [];
      res.forEach(function(rowData) {
        if (rowData.values) {
          //console.log("rd",JSON.stringify(rowData))
          returnResult.push(RowFactory.createLocal(rowData.values, rowData.schema))
        } else {
          returnResult.push(rowData);
        }
      });
    } else {
      returnResult = RowFactory.createLocal(res.values, res.schema);
    }

    resolve(returnResult);
  } catch (e) {
    var err = new Error("Parse Error: "+ e.message);
    reject(err);
  }
}

function Dataset(kernelP, refIdP) {
  this.kernelP = kernelP;
  this.refIdP = refIdP;

  //Utils.handleConstructor(this, arguments, gKernelP);
}

/**
 * @returns {Promise.&lt;string>}
 */
Dataset.prototype.toString = function() {
  var args = {
    target: this,
    method: 'toString',
    returnType: String
  };

  return Utils.generate(args);
};

/**
 * aggregates on the entire Dataset without groups.
 * @example
 * // df.agg(...) is a shorthand for df.groupBy().agg(...)
 * var map = {};
 * map["age"] = "max";
 * map["salary"] = "avg";
 * df.agg(map)
 * df.groupBy().agg(map)
 * @function
 * @name module:eclairjs/sql.Dataset#agg
 * @param {hashMap} - hashMap&lt;String,String> exprs
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.agg = function() {
  var args = {
    target: this,
    method: 'agg',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * :: Experimental ::
 * Returns a new Dataset where each record has been mapped on to the specified type. The
 * method used to map columns depend on the type of `U`:
 *  - When `U` is a class, fields for the class will be mapped to columns of the same name
 *    (case sensitivity is determined by `spark.sql.caseSensitive`).
 *  - When `U` is a tuple, the columns will be be mapped by ordinal (i.e. the first column will
 *    be assigned to `_1`).
 *  - When `U` is a primitive type (i.e. String, Int, etc), then the first column of the
 *    {@link Dataset} will be used.
 *
 * If the schema of the Dataset does not match the desired `U` type, you can use `select`
 * along with `alias` or `as` to rearrange or rename as required.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.as = function() {
  var args = {
    target: this,
    method: 'as',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Converts this strongly typed collection of data to generic `Dataset` with columns renamed.
 * This can be quite convenient in conversion from a RDD of tuples into a {@link Dataset} with
 * meaningful names. For example:
 * @example
 *   val rdd: RDD[(Int, String)] = ...
 *   rdd.toDF()  // this implicit conversion creates a Dataset with column name `_1` and `_2`
 *   rdd.toDF("id", "name")  // this creates a Dataset with column name "id" and "name"
 *
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {...string} [colNames]
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.toDF = function(colNames) {
  var Dataset = require('./Dataset');

  var args = {
    target: this,
    method: 'toDF',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns the schema of this Dataset.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {StructType}
 */
Dataset.prototype.schema = function() {
  var StructType = require('./types/StructType.js')(this.kernelP);

  var args = {
    target: this,
    method: 'schema',
    returnType: StructType
  };

  return Utils.generate(args);
};

/**
 * Prints the schema to the console in a nice tree format.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {Promise.&lt;Void>} A Promise that resolves to nothing.
 */
Dataset.prototype.printSchema = function() {
  throw "not implemented by ElairJS";
};

/**
 * Prints the plans (logical and physical) to the console for debugging purposes.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @param {boolean} if false prints the physical plans only.
 * @returns {Promise.&lt;Void>} A Promise that resolves to nothing.
 */
Dataset.prototype.explain = function(extended) {
  var args = {
    target: this,
    method: 'explain',
    args: Utils.wrapArguments(arguments),
    returnType: null
  };

  return Utils.generate(args);
};

/**
 * Returns all column names and their data types as an array.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {Promise.&lt;Array>} A Promise that resolves to an Array of Array[2].
 */
Dataset.prototype.dtypes = function() {
  var args = {
    target: this,
    method: 'dtypes',
    stringify: true,
    returnType: [String],
  };

  return Utils.generate(args);
};

/**
 * Returns all column names as an array.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {Promise.&lt;string[]>}
 */
Dataset.prototype.columns = function() {
  var args = {
    target: this,
    method: 'columns',
    returnType: [String],
    stringify: true
  };

  return Utils.generate(args);
};

/**
 * Returns true if the `collect` and `take` methods can be run locally
 * (without any Spark executors).
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {Promise.&lt;boolean>}
 */
Dataset.prototype.isLocal = function() {
  var args = {
    target: this,
    method: 'isLocal',
    returnType: Boolean
  };

  return Utils.generate(args);
};

/**
 * Returns true if this Dataset contains one or more sources that continuously
 * return data as it arrives. A Dataset that reads data from a streaming source
 * must be executed as a {@link StreamingQuery} using the `start()` method in
 * {@link DataStreamWriter}. Methods that return a single answer, e.g. `count()` or
 * `collect()`, will throw an {@link AnalysisException} when there is a streaming
 * source present.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @returns {Promise.&lt;boolean>}
 */
Dataset.prototype.isStreaming = function() {
  var args = {
    target: this,
    method: 'isStreaming',
    returnType: Boolean
  };

  return Utils.generate(args);
};

/**
 * Displays the Dataset rows in a tabular form.
 * @function
 * @name module:eclairjs/sql.Dataset#show
 * @param {interger} [numberOfRows] defaults to 20.
 * @param {boolean] [truncate] defaults to false, Whether truncate long strings. If true, strings more than 20 characters will be
 * truncated and all cells will be aligned right
 */
Dataset.prototype.show = function(numRows) {
  throw "not implemented by ElairJS";
//   var args = {
//     target: this,
//     method: 'show',
//     args: Utils.wrapArguments(arguments),
//     returnType: null
//
//   };
//
//   return Utils.generate(args);
};

/**
 * Returns a {@link DataFrameNaFunctions} for working with missing data.
 * @example
 *   // Dropping rows containing any null values.
 *   ds.na.drop()
 *
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {module:eclairjs/sql.DataFrameNaFunctions}
 */
Dataset.prototype.na = function() {
  var DataFrameNaFunctions = require('./DataFrameNaFunctions.js');

  var args = {
    target: this,
    method: 'na',
    returnType: DataFrameNaFunctions
  };

  return Utils.generate(args);
};

/**
 * Returns a {@link DataFrameStatFunctions} for working statistic functions support.
 * @example
 *   // Finding frequent items in column with name 'a'.
 *   ds.stat.freqItems(Seq("a"))
 *
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {DataFrameStatFunctions}
 */
Dataset.prototype.stat = function() {
  var DataFrameStatFunctions = require('./DataFrameStatFunctions.js');

  var args = {
    target: this,
    method: 'stat',
    returnType: DataFrameStatFunctions
  };

  return Utils.generate(args);
};

/**
 * Cartesian join with another Dataset. Note that cartesian joins are very expensive without an extra filter that can be pushed down.
 * @function
 * @name module:eclairjs/sql.Dataset#join
 * @param {module:eclairjs/sql.Dataset} Right side of the join operation.
 * @param {string | string[] | module:eclairjs/sql.Column} [columnNamesOrJoinExpr] If string or array of strings column names, inner equi-join with another Dataset using the given columns.
 * Different from other join functions, the join columns will only appear once in the output, i.e. similar to SQL's JOIN USING syntax.
 * If Column object, joinExprs inner join with another Dataset, using the given join expression.
 * @param {string} [joinType] only valid if using Column joinExprs.
 * @returns {module:eclairjs/sql.Dataset}
 * @example
 * var joinedDf = df1.join(df2);
 * // or
 * var joinedDf = df1.join(df2,"age");
 * // or
 * var joinedDf = df1.join(df2, ["age", "DOB"]);
 * // or Column joinExpr
 * var joinedDf = df1.join(df2, df1.col("name").equalTo(df2.col("name")));
 * // or Column joinExpr
 * var joinedDf = df1.join(df2, df1.col("name").equalTo(df2.col("name")), "outer");
 */
Dataset.prototype.join = function() {
  var args = {
    target: this,
    method: 'join',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * :: Experimental ::
 * Joins this Dataset returning a {@link Tuple2} for each pair where `condition` evaluates to
 * true.
 *
 * This is similar to the relation `join` function with one important difference in the
 * result schema. Since `joinWith` preserves objects present on either side of the join, the
 * result schema is similarly nested into a tuple under the column names `_1` and `_2`.
 *
 * This type of join can be useful both for preserving type-safety with the original object
 * types as well as working with relational data where either side of the join has column
 * names in common.
 *
 * @param {module:eclairjs/sql.Dataset} other  Right side of the join.
 * @param {module:eclairjs/sql.Column} condition  Join expression.
 * @param {string} [joinType]  One of: `inner`, `outer`, `left_outer`, `right_outer`, `leftsemi`.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.joinWith = function(other,condition,joinType) {
  var args = {
    target: this,
    method: 'joinWith',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset with each partition sorted by the given expressions.
 *
 * This is the same operation as "SORT BY" in SQL (Hive QL).
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {...module:eclairjs/sql.Column} sortExprs
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.sortWithinPartitions = function(sortExprs) {
  var args = {
    target: this,
    method: 'sortWithinPartitions',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset sorted by the given expressions. For example:
 * @example
 *   ds.sort($"col1", $"col2".desc)
 *
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {...module:eclairjs/sql.Column} sortExprs
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.sort = function() {
  var args = {
    target: this,
    method: 'sort',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset sorted by the specified columns, if columnName is used sorted in ascending order.
 * This is an alias of the sort function.
 * @function
 * @name module:eclairjs/sql.Dataset#orderBy
 * @param {string | module:eclairjs/sql.Column} columnName,...columnName or sortExprs,... sortExprs
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.orderBy = function(sortExprs) {
  var args = {
    target: this,
    method: 'orderBy',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Selects column based on the column name and return it as a {@link Column}.
 * Note that the column name can also reference to a nested column like `a.b`.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {string} colName
 * @returns {module:eclairjs/sql.Column}
 */
Dataset.prototype.apply = function(colName) {
  var Column = require('./Column');

  var args = {
    target: this,
    method: 'apply',
    args: Utils.wrapArguments(arguments),
    returnType: Column
  };

  return Utils.generate(args);
};

/**
 * Selects column based on the column name and return it as a {@link Column}.
 * Note that the column name can also reference to a nested column like `a.b`.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {string} colName
 * @returns {module:eclairjs/sql.Column}
 */
Dataset.prototype.col = function(colName) {
  var Column = require('./Column');

  var args = {
    target: this,
    method: 'col',
    args: Utils.wrapArguments(arguments),
    returnType: Column
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset with an alias set. Same as `as`.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {string} alias
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.alias = function(alias) {
  var args = {
    target: this,
    method: 'alias',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Selects a set of column based expressions.
 * @function
 * @name module:eclairjs/sql.Dataset#select
 * @param {module:eclairjs/sql.Column[] | module:eclairjs/sql.TypedColumn[] | string[]}
 * @returns  {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.select = function() {
  var args = {
    target: this,
    method: 'select',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Selects a set of SQL expressions. This is a variant of `select` that accepts
 * SQL expressions.
 *
 * @example
 *   // The following are equivalent:
 *   ds.selectExpr("colA", "colB as newName", "abs(colC)")
 *   ds.select(expr("colA"), expr("colB as newName"), expr("abs(colC)"))
 *
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {...string} exprs
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.selectExpr = function() {
  var args = {
    target: this,
    method: 'selectExpr',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Filters rows using the given condition.
 * @example
 *   // The following are equivalent:
 *   peopleDs.filter($"age" > 15)
 *   peopleDs.where($"age" > 15)
 *
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @param {string | module:eclairjs/sql.Column}
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.filter = function() {
  var args = {
    target: this,
    method: 'filter',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Filters rows using the given Column or SQL expression.
 * @function
 * @name module:eclairjs/sql.Dataset#where
 * @param {module:eclairjs/sql.Column | string} condition - .
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.where = function(condition) {
  var args = {
    target: this,
    method: 'where',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Groups the Dataset using the specified columns, so we can run aggregation on them. See
 * {@link RelationalGroupedDataset} for all the available aggregate functions.
 *
 * @example
 *   // Compute the average for all numeric columns grouped by department.
 *   ds.groupBy($"department").avg()
 *
 *   // Compute the max age and average salary, grouped by department and gender.
 *   ds.groupBy($"department", $"gender").agg(Map(
 *     "salary" -> "avg",
 *     "age" -> "max"
 *   ))
 *
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {string[] | module:eclairjs/sql.Column[]} - Array of Column objects of column name strings
 * @returns {module:eclairjs/sql.RelationalGroupedDataset}
 */
Dataset.prototype.groupBy = function(cols) {
  var RelationalGroupedDataset = require('./RelationalGroupedDataset');

  var args = {
    target: this,
    method: 'groupBy',
    args: Utils.wrapArguments(arguments),
    returnType: RelationalGroupedDataset
  };

  return Utils.generate(args);
};

/**
 * Create a multi-dimensional rollup for the current Dataset using the specified columns,
 * so we can run aggregation on them.
 * See {@link RelationalGroupedDataset} for all the available aggregate functions.
 *
 * @example
 *   // Compute the average for all numeric columns rolluped by department and group.
 *   ds.rollup($"department", $"group").avg()
 *
 *   // Compute the max age and average salary, rolluped by department and gender.
 *   ds.rollup($"department", $"gender").agg(Map(
 *     "salary" -> "avg",
 *     "age" -> "max"
 *   ))
 *
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {...module:eclairjs/sql.Column} cols
 * @returns {module:eclairjs/sql.RelationalGroupedDataset}
 */
Dataset.prototype.rollup = function(cols) {
  var RelationalGroupedDataset = require('./RelationalGroupedDataset');

  var args = {
    target: this,
    method: 'rollup',
    args: Utils.wrapArguments(arguments),
    returnType: RelationalGroupedDataset
  };

  return Utils.generate(args);
};

/**
 * Create a multi-dimensional cube for the current Dataset using the specified columns,
 * so we can run aggregation on them.
 * See {@link RelationalGroupedDataset} for all the available aggregate functions.
 *
 * @example
 *   // Compute the average for all numeric columns cubed by department and group.
 *   ds.cube($"department", $"group").avg()
 *
 *   // Compute the max age and average salary, cubed by department and gender.
 *   ds.cube($"department", $"gender").agg(Map(
 *     "salary" -> "avg",
 *     "age" -> "max"
 *   ))
 *
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {...module:eclairjs/sql.Column} cols
 * @returns {module:eclairjs/sql.RelationalGroupedDataset}
 */
Dataset.prototype.cube = function(cols) {
  var RelationalGroupedDataset = require('./RelationalGroupedDataset');

  var args = {
    target: this,
    method: 'cube',
    args: Utils.wrapArguments(arguments),
    returnType: RelationalGroupedDataset
  };

  return Utils.generate(args);
};

/**
 * :: Experimental ::
 * Returns a {@link KeyValueGroupedDataset} where the data is grouped by the given key `func`.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {function} func
 * @param {module:eclairjs/sql.Encoder} encoder
 * @returns {module:eclairjs/sql.KeyValueGroupedDataset}
 */
Dataset.prototype.groupByKey = function(func) {
  throw "not implemented by ElairJS";
// var KeyValueGroupedDataset = require('../sql/KeyValueGroupedDataset.js');
//   var args = {
//     target: this,
//     method: 'groupByKey',
//     args: Utils.wrapArguments(arguments),
//     returnType: KeyValueGroupedDataset
//
//   };
//
//   return Utils.generate(args);
};

/**
 * Returns a new Dataset by taking the first `n` rows. The difference between this function
 * and `head` is that `head` is an action and returns an array (by triggering query execution)
 * while `limit` returns a new Dataset.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {number} n
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.limit = function(n) {
  var args = {
    target: this,
    method: 'limit',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset containing union of rows in this Dataset and another Dataset.
 * This is equivalent to `UNION ALL` in SQL.
 *
 * To do a SQL-style set union (that does deduplication of elements), use this function followed
 * by a {@link distinct}.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {module:eclairjs/sql.Dataset} other
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.unionAll = function(other) {
  var args = {
    target: this,
    method: 'unionAll',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset containing union of rows in this Dataset and another Dataset.
 * This is equivalent to `UNION ALL` in SQL.
 *
 * To do a SQL-style set union (that does deduplication of elements), use this function followed
 * by a {@link distinct}.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {module:eclairjs/sql.Dataset} other
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.union = function(other) {
  var args = {
    target: this,
    method: 'union',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset containing rows only in both this Dataset and another Dataset.
 * This is equivalent to `INTERSECT` in SQL.
 *
 * Note that, equality checking is performed directly on the encoded representation of the data
 * and thus is not affected by a custom `equals` function defined on `T`.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @param {module:eclairjs/sql.Dataset} other
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.intersect = function(other) {
  var args = {
    target: this,
    method: 'intersect',
    args: Utils.wrapArguments(arguments),
   returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset containing rows in this Dataset but not in another Dataset.
 * This is equivalent to `EXCEPT` in SQL.
 *
 * Note that, equality checking is performed directly on the encoded representation of the data
 * and thus is not affected by a custom `equals` function defined on `T`.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {module:eclairjs/sql.Dataset} other
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.except = function(other) {
  var args = {
    target: this,
    method: 'except',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset by sampling a fraction of rows.
 *
 * @param {boolean} withReplacement  Sample with replacement or not.
 * @param {number} fraction  Fraction of rows to generate.
 * @param {number} [seed]  Seed for sampling.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.sample = function(withReplacement,fraction,seed) {
  var args = {
    target: this,
    method: 'sample',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Randomly splits this Dataset with the provided weights.
 *
 * @param {number[]} weights  weights for splits, will be normalized if they don't sum to 1.
 * @param {number} [seed]  Seed for sampling.
 *
 * For Java API, use {@link randomSplitAsList}.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @returns {Dataset[]}
 */
Dataset.prototype.randomSplit = function(weights, seed) {
  var args = {
    target: this,
    method: 'randomSplit',
    args: [
      {value: Utils.wrapArray(weights)},
      {value: seed, type: 'number', optional: true}
    ],
    returnType: [Dataset]
  };

  return Utils.generate(args);
};

/**
 * (Scala-specific) Returns a new Dataset where each row has been expanded to zero or more
 * rows by the provided function. This is similar to a `LATERAL VIEW` in HiveQL. The columns of
 * the input row are implicitly joined with each row that is output by the function.
 *
 * Given that this is deprecated, as an alternative, you can explode columns either using
 * `functions.explode()` or `flatMap()`. The following example uses these alternatives to count
 * the number of books that contain a given word:
 *
 * @example
 *   case class Book(title: String, words: String)
 *   val ds: Dataset[Book]
 *
 *   val allWords = ds.select('title, explode(split('words, " ")).as("word"))
 *
 *   val bookCountPerWord = allWords.groupBy("word").agg(countDistinct("title"))
 *
 *
 * Using `flatMap()` this can similarly be exploded as:
 *
 * @example
 *   ds.flatMap(_.words.split(" "))
 *
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {...module:eclairjs/sql.Column} input
 * @param {func} f
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.explode = function(input,f) {
  throw "not implemented by ElairJS";
// // TODO: handle repeated parm 'input'
//   var args = {
//     target: this,
//     method: 'explode',
//     args: Utils.wrapArguments(arguments),
//     returnType: Dataset
//
//   };
//
//   return Utils.generate(args);
};


/**
 * (Scala-specific) Returns a new Dataset where a single column has been expanded to zero
 * or more rows by the provided function. This is similar to a `LATERAL VIEW` in HiveQL. All
 * columns of the input row are implicitly joined with each value that is output by the function.
 *
 * Given that this is deprecated, as an alternative, you can explode columns either using
 * `functions.explode()`:
 *
 * @example
 *   ds.select(explode(split('words, " ")).as("word"))
 *
 *
 * or `flatMap()`:
 *
 * @example
 *   ds.flatMap(_.words.split(" "))
 *
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {string} inputColumn
 * @param {string} outputColumn
 * @param {func} f
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.explodewithF = function(inputColumn,outputColumn,f) {
  throw "not implemented by ElairJS";
//   var args = {
//     target: this,
//     method: 'explode',
//     args: Utils.wrapArguments(arguments),
//     returnType: Dataset
//
//   };
//
//   return Utils.generate(args);
};

/**
 * Returns a new Dataset by adding a column or replacing the existing column that has
 * the same name.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {string} colName
 * @param {module:eclairjs/sql.Column} col
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.withColumn = function(colName,col) {
  var args = {
    target: this,
    method: 'withColumn',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset with a column renamed.
 * This is a no-op if schema doesn't contain existingName.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {string} existingName
 * @param {string} newName
 * @returns {module:eclairjs/sql/types.StructType}
 */
Dataset.prototype.withColumnRenamed = function(existingName,newName) {
  var args = {
    target: this,
    method: 'withColumnRenamed',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset with a columns dropped. This is a no-op if schema doesn't contain
 * column name(s).
 *
 * This method can only be used to drop top level columns. the colNames string is treated
 * literally without further interpretation.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {string} colNames...
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.drop = function() {
  var args = {
    target: this,
    method: 'drop',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset that contains only the unique rows from this Dataset, if colNames then considering only the subset of columns.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {string} colNames...
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.dropDuplicates = function() {
  var args = {
    target: this,
    method: 'dropDuplicates',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Computes statistics for numeric and string columns, including count, mean, stddev, min, and
 * max. If no columns are given, this function computes statistics for all numerical or string
 * columns.
 *
 * This function is meant for exploratory data analysis, as we make no guarantee about the
 * backward compatibility of the schema of the resulting Dataset. If you want to
 * programmatically compute summary statistics, use the `agg` function instead.
 *
 * @example
 *   ds.describe("age", "height").show()
 *
 *   // output:
 *   // summary age   height
 *   // count   10.0  10.0
 *   // mean    53.3  178.05
 *   // stddev  11.6  15.7
 *   // min     18.0  163.0
 *   // max     92.0  192.0
 *
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @param {string} cols...
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.describe = function(cols) {
  var args = {
    target: this,
    method: 'describe',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns the first `n` rows.
 *
 * @note this method should only be used if the resulting array is expected to be small, as
 * all the data is loaded into the driver's memory.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @param {number} [n]
 * @returns {module:eclairjs/sql.Row}
 */
Dataset.prototype.head = function(n) {
  var Row = require('./Row')();

  var args = {
    target: this,
    method: 'head',
    returnType: Row
  };

  return Utils.generate(args);
};

/**
 * Returns the first row. Alias for head().
 * @since EclairJS 0.7 Spark  1.6.0
 * returns {module:eclairjs/sql.Row}
 */
Dataset.prototype.first = function() {
  var Row = require('./Row')();

   var args = {
    target: this,
    method: 'first',
    returnType: String,
    stringify: true,
    resolver: _resolveRows.bind(this)
  };

  return Utils.generate(args);
};

/**
 * Concise syntax for chaining custom transformations.
 * @example
 *   def featurize(ds: Dataset[T]): Dataset[U] = ...
 *
 *   ds
 *     .transform(featurize)
 *     .transform(...)
 *
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @param {func} t
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.transform = function(t) {
  var args = {
    target: this,
    method: 'transform',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * :: Experimental ::
 * (Scala-specific)
 * Returns a new Dataset that contains the result of applying `func` to each element.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @param {function} func
 * @param {module:eclairjs/sql.Encoder} encoder
 * @param {Object[]} [bindArgs] array whose values will be added to func's argument list.
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.map = function(func, encoder, bindArgs) {
  var args = {
    target: this,
    method: 'map',
    args: [
      {value: func, type: 'lambda'},
      {value: encoder},
      {value: Utils.wrapBindArgs(bindArgs), optional: true}
    ],
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * :: Experimental ::
 * (Scala-specific)
 * Returns a new Dataset that contains the result of applying `func` to each partition.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @param {function}
 * @param {module:eclairjs/sql.Encoder} encoder
 * @param {Object[]} [bindArgs] array whose values will be added to func's argument list.
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.mapPartitions = function(func, encoder, bindArgs) {
  var args = {
    target: this,
    method: 'mapPartitions',
    args: [
      {value: func, type: 'lambda'},
      {value: encoder},
      {value: Utils.wrapBindArgs(bindArgs), optional: true}
    ],
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset by first applying a function to all elements of this Dataset,
 * and then flattening the results.
 * @function
 * @name module:eclairjs/sql.Dataset#flatMap
 * @param {function} func
 * @param {module:eclairjs/sql.Encoder} encoder
 * @param {Object[]} [bindArgs] array whose values will be added to func's argument list.
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.flatMap = function(func, encoder, bindArgs) {
  var args = {
    target: this,
    method: 'flatMap',
    args: [
      {value: func, type: 'lambda'},
      {value: encoder},
      {value: Utils.wrapBindArgs(bindArgs), optional: true}
    ],
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Applies a function to all elements of this Dataset.
 * @example
 * rdd3.foreach(function(record) {
	 *    var connection = createNewConnection()
	 *    connection.send(record);
	 *    connection.close()
	 * });
 * @function
 * @name module:eclairjs/sql.Dataset#foreach
 * @param {function} Function with one parameter
 * @param {Object[]} [bindArgs] array whose values will be added to func's argument list.
 * @returns {Promise.&lt;Void>} A Promise that resolves to nothing.
 */
Dataset.prototype.foreach = function(func, bindArgs) {
  var args = {
    target: this,
    method: 'flatMap',
    args: [
      {value: func, type: 'lambda'},
      {value: Utils.wrapBindArgs(bindArgs), optional: true}
    ],
    returnType: null
  };

  return Utils.generate(args);
};

/**
 * Applies a function `f` to each partition of this Dataset.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @param {function} Function with one Array parameter
 * @param {Object[]} [bindArgs] array whose values will be added to func's argument list.
 * @returns {Promise.&lt;Void>} A Promise that resolves to nothing.
 */
Dataset.prototype.foreachPartition = function(func, bindArgs) {
  var args = {
    target: this,
    method: 'foreachPartition',
    args: [
      {value: func, type: 'lambda'},
      {value: Utils.wrapBindArgs(bindArgs), optional: true}
    ],
    returnType: null
  };

  return Utils.generate(args);
};

/**
 * Returns the first `n` rows in the Dataset.
 *
 * Running take requires moving data into the application's driver process, and doing so with
 * a very large `n` can crash the driver process with OutOfMemoryError.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @param {number} n
 * @returns {Promise.&lt;object[]>}
 */
Dataset.prototype.take = function(n) {
  var args = {
    target: this,
    method: 'take',
    args: Utils.wrapArguments(arguments),
    returnType: String,
    stringify: true,
    resolver: _resolveRows.bind(this)
  };

  return Utils.generate(args);
};

/**
 * Returns an array that contains all of {@link Row}s in this Dataset.
 *
 * Running collect requires moving all the data into the application's driver process, and
 * doing so on a very large dataset can crash the driver process with OutOfMemoryError.
 *
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {Promise.&lt;object[]>}
 */
Dataset.prototype.collect = function() {
  var args = {
    target: this,
    method: 'collect',
    returnType: String,
    stringify: true,
    resolver: _resolveRows.bind(this)
  };

  return Utils.generate(args);
};

/**
 * Return an iterator that contains all of {@link Row}s in this Dataset.
 *
 * The iterator will consume as much memory as the largest partition in this Dataset.
 *
 * Note: this results in multiple Spark jobs, and if the input Dataset is the result
 * of a wide transformation (e.g. join with different partitioners), to avoid
 * recomputing the input Dataset should be cached first.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @returns {Iterator}
 */
Dataset.prototype.toLocalIterator = function() {
  throw "not implemented by ElairJS";
//   var args = {
//     target: this,
//     method: 'toLocalIterator',
//     returnType: Iterator
//
//   };
//
//   return Utils.generate(args);
};

/**
 * Returns the number of rows in the Dataset.
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {Promise.&lt;number>}
 */
Dataset.prototype.count = function() {
   var args = {
     target: this,
     method: 'count',
     returnType: Number
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset that has exactly `numPartitions` partitions.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @param {number} numPartitions
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.repartition = function(numPartitions) {
  var args = {
    target: this,
    method: 'repartition',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset that has exactly `numPartitions` partitions.
 * Similar to coalesce defined on an {@link RDD}, this operation results in a narrow dependency, e.g.
 * if you go from 1000 partitions to 100 partitions, there will not be a shuffle, instead each of
 * the 100 new partitions will claim 10 of the current partitions.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @param {number} numPartitions
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.coalesce = function(numPartitions) {
  var args = {
    target: this,
    method: 'coalesce',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a new Dataset that contains only the unique rows from this Dataset.
 * This is an alias for `dropDuplicates`.
 *
 * Note that, equality checking is performed directly on the encoded representation of the data
 * and thus is not affected by a custom `equals` function defined on `T`.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.distinct = function() {
  var args = {
    target: this,
    method: 'distinct',
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Persist this Dataset with the default storage level (`MEMORY_ONLY`).
 * @function
 * @name module:eclairjs/sql.Dataset#cache
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.cache = function() {
  var args = {
    target: this,
    method: 'cache',
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Persist this Dataset with the given storage level.
 * @param {module:eclairjs/storage.StorageLevel} [newLevel]  One of: `MEMORY_ONLY`, `MEMORY_AND_DISK`, `MEMORY_ONLY_SER`,
 *                 `MEMORY_AND_DISK_SER`, `DISK_ONLY`, `MEMORY_ONLY_2`,
 *                 `MEMORY_AND_DISK_2`, etc.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.persist = function(newLevel) {
  var args = {
    target: this,
    method: 'persist',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Mark the Dataset as non-persistent, and remove all blocks for it from memory and disk.
 *
 * @param {boolean} [blocking]  Whether to block until all blocks are deleted.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.unpersist = function(blocking) {
  var args = {
    target: this,
    method: 'unpersist',
    args: Utils.wrapArguments(arguments),
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Registers this Dataset as a temporary table using the given name. The lifetime of this
 * temporary table is tied to the {@link SparkSession} that was used to create this Dataset.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @param {string} tableName
 * @returns {Promise.&lt;Void>} A Promise that resolves to nothing.
 */
Dataset.prototype.registerTempTable = function(tableName) {
  var args = {
    target: this,
    method: 'registerTempTable',
    args: Utils.wrapArguments(arguments),
    returnType: null
  };

  return Utils.generate(args);
};

/**
 * Creates a temporary view using the given name. The lifetime of this
 * temporary view is tied to the {@link SparkSession} that was used to create this Dataset.
 *
 * @throws AnalysisException if the view name already exists
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {string} viewName
 * @returns {Promise.&lt;Void>} A Promise that resolves to nothing.
 */
Dataset.prototype.createTempView = function(viewName) {
  throw "not implemented by ElairJS";
//   var args = {
//     target: this,
//     method: 'createTempView',
//     args: Utils.wrapArguments(arguments),
//     returnType: null
//
//   };
//
//   return Utils.generate(args);
};

/**
 * Creates a temporary view using the given name. The lifetime of this
 * temporary view is tied to the {@link SparkSession} that was used to create this Dataset.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @param {string} viewName
 * @returns {Promise.&lt;Void>} A Promise that resolves to nothing.
 */
Dataset.prototype.createOrReplaceTempView = function(viewName) {
  var args = {
    target: this,
    method: 'createOrReplaceTempView',
    args: Utils.wrapArguments(arguments),
    returnType: null
  };

  return Utils.generate(args);
};

/**
 * :: Experimental ::
 * Interface for saving the content of the non-streaming Dataset out into external storage.
 *
 * @since EclairJS 0.7 Spark  1.6.0
 * @returns {module:eclairjs/sql.DatasetWriter}
 */
Dataset.prototype.write = function() {
  var DataFrameWriter = require('../sql/DataFrameWriter.js');
  var args = {
    target: this,
    method: 'write',
    returnType: DataFrameWriter
  };

  return Utils.generate(args);
};

/**
 * :: Experimental ::
 * Interface for saving the content of the streaming Dataset out into external storage.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @returns {module:eclairjs/sql/streaming.DataStreamWriter}
 */
Dataset.prototype.writeStream = function() {
	 var DataStreamWriter = require('../sql/streaming/DataStreamWriter.js');
	   var args = {
	     target: this,
	     method: 'writeStream',
	     returnType: DataStreamWriter

	   };

	   return Utils.generate(args);
};

/**
 * Returns the content of the Dataset as a Dataset of JSON strings.
 * @since EclairJS 0.7 Spark  2.0.0
 * @returns {module:eclairjs/sql.Dataset}
 */
Dataset.prototype.toJSON = function() {
  var args = {
    target: this,
    method: 'toJSON',
    returnType: Dataset
  };

  return Utils.generate(args);
};

/**
 * Returns a best-effort snapshot of the files that compose this Dataset. This method simply
 * asks each constituent BaseRelation for its respective files and takes the union of all results.
 * Depending on the source relations, this may not find all input files. Duplicates are removed.
 *
 * @since EclairJS 0.7 Spark  2.0.0
 * @returns {Promise.&lt;string[]>}
 */
Dataset.prototype.inputFiles = function() {
  var args = {
    target: this,
    method: 'inputFiles',
    stringify: true,
    returnType: [String]
  };

  return Utils.generate(args);
};

/**
 * @function
 * @name module:eclairjs/sql.Dataset#queryExecution
 * @returns {module:eclairjs/sql.SQLContextQueryExecution}
 */
Dataset.prototype.queryExecution = function() {
  var SQLContextQueryExecution = require('./SQLContextQueryExecution');

  var args = {
    target: this,
    method: 'queryExecution',
    returnType: SQLContextQueryExecution
  };

  return Utils.generate(args);
};

/**
 * Represents the content of the Dataset as an RDD of Rows.
 * @function
 * @name module:eclairjs/sql.Dataset#rdd
 * @returns {module:eclairjs.RDD}
 */
Dataset.prototype.rdd = function () {
  var RDD = require('../rdd/RDD.js');

  var args = {
    target: this,
    method: 'rdd',
    returnType: RDD
  };

  return Utils.generate(args);
};

/**
 * Represents the content of the Dataset as an RDD of Rows.
 * @function
 * @name module:eclairjs/sql.Dataset#rdd
 * @returns {module:eclairjs.RDD}
 */
Dataset.prototype.toRDD = function () {
  var RDD = require('../rdd/RDD.js');

  var args = {
    target: this,
    method: 'toRDD',
    returnType: RDD
  };

  return Utils.generate(args);
};

/**
 * Returns the first row.
 * @function
 * @name module:eclairjs/sql.Dataset#head
 * @param {number} [n]
 * @returns {module:eclairjs/sql.Row}
 */
Dataset.prototype.head = function () {
  var Row = require('./Row')();

  var args = {
    target: this,
    method: 'head',
    args: Utils.wrapArguments(arguments),
    returnType: String,
    stringify: true,
    resolver: _resolveRows.bind(this)
  };

  return Utils.generate(args);
};

/**
 * Returns SQLContext
 * @returns {module:eclairjs/sql.SQLContext}
 */
Dataset.prototype.sqlContext = function() {
  var Dataset = require('./SQLContext.js');

  // TODO: need a cleaner way
  return new SQLContext({context: this.kernelP});
};

Dataset.moduleLocation = '/sql/Dataset';
module.exports = Dataset;
//module.exports = function(kP) {
//  if (kP) gKernelP = kP;
//
//  return Dataset;
//};
</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Modules</h3><ul><li><a href="module-eclairjs.html">eclairjs</a></li><li><a href="module-eclairjs_ml.html">eclairjs/ml</a></li><li><a href="module-eclairjs_ml_classification.html">eclairjs/ml/classification</a></li><li><a href="module-eclairjs_ml_clustering.html">eclairjs/ml/clustering</a></li><li><a href="module-eclairjs_ml_evaluation.html">eclairjs/ml/evaluation</a></li><li><a href="module-eclairjs_ml_feature.html">eclairjs/ml/feature</a></li><li><a href="module-eclairjs_ml_param.html">eclairjs/ml/param</a></li><li><a href="module-eclairjs_ml_recommendation.html">eclairjs/ml/recommendation</a></li><li><a href="module-eclairjs_ml_regression.html">eclairjs/ml/regression</a></li><li><a href="module-eclairjs_ml_tuning.html">eclairjs/ml/tuning</a></li><li><a href="module-eclairjs_mllib.html">eclairjs/mllib</a></li><li><a href="module-eclairjs_mllib_classification.html">eclairjs/mllib/classification</a></li><li><a href="module-eclairjs_mllib_clustering.html">eclairjs/mllib/clustering</a></li><li><a href="module-eclairjs_mllib_evaluation.html">eclairjs/mllib/evaluation</a></li><li><a href="module-eclairjs_mllib_feature.html">eclairjs/mllib/feature</a></li><li><a href="module-eclairjs_mllib_fpm.html">eclairjs/mllib/fpm</a></li><li><a href="module-eclairjs_mllib_linalg.html">eclairjs/mllib/linalg</a></li><li><a href="module-eclairjs_mllib_linalg_distributed.html">eclairjs/mllib/linalg/distributed</a></li><li><a href="module-eclairjs_mllib_optimization.html">eclairjs/mllib/optimization</a></li><li><a href="module-eclairjs_mllib_random.html">eclairjs/mllib/random</a></li><li><a href="module-eclairjs_mllib_recommendation.html">eclairjs/mllib/recommendation</a></li><li><a href="module-eclairjs_mllib_regression.html">eclairjs/mllib/regression</a></li><li><a href="module-eclairjs_mllib_tree.html">eclairjs/mllib/tree</a></li><li><a href="module-eclairjs_mllib_tree_configuration.html">eclairjs/mllib/tree/configuration</a></li><li><a href="module-eclairjs_mllib_tree_loss.html">eclairjs/mllib/tree/loss</a></li><li><a href="module-eclairjs_mllib_tree_model.html">eclairjs/mllib/tree/model</a></li><li><a href="module-eclairjs_mllib_util.html">eclairjs/mllib/util</a></li><li><a href="module-eclairjs_rdd.html">eclairjs/rdd</a></li><li><a href="module-eclairjs_sql.html">eclairjs/sql</a></li><li><a href="module-eclairjs_sql_streaming.html">eclairjs/sql/streaming</a></li><li><a href="module-eclairjs_sql_types.html">eclairjs/sql/types</a></li><li><a href="module-eclairjs_storage.html">eclairjs/storage</a></li><li><a href="module-eclairjs_streaming.html">eclairjs/streaming</a></li><li><a href="module-eclairjs_streaming_dstream.html">eclairjs/streaming/dstream</a></li><li><a href="module-eclairjs_streaming_kafka.html">eclairjs/streaming/kafka</a></li><li><a href="module-eclairjs_streaming_twitter.html">eclairjs/streaming/twitter</a></li></ul><h3>Classes</h3><ul><li><a href="-_resolveRows.html">_resolveRows</a></li><li><a href="InputDStream.html">InputDStream</a></li><li><a href="IsotonicRegressionModel.html">IsotonicRegressionModel</a></li><li><a href="MLReader.html">MLReader</a></li><li><a href="MLWriter.html">MLWriter</a></li><li><a href="module-eclairjs.Accumulable.html">Accumulable</a></li><li><a href="module-eclairjs.AccumulableParam.html">AccumulableParam</a></li><li><a href="module-eclairjs.Accumulator.html">Accumulator</a></li><li><a href="module-eclairjs.FloatAccumulatorParam.html">FloatAccumulatorParam</a></li><li><a href="module-eclairjs.IntAccumulatorParam.html">IntAccumulatorParam</a></li><li><a href="module-eclairjs.List.html">List</a></li><li><a href="module-eclairjs.SparkConf.html">SparkConf</a></li><li><a href="module-eclairjs.SparkContext.html">SparkContext</a></li><li><a href="module-eclairjs.Tuple.html">Tuple</a></li><li><a href="module-eclairjs.Tuple2.html">Tuple2</a></li><li><a href="module-eclairjs.Tuple3.html">Tuple3</a></li><li><a href="module-eclairjs.Tuple4.html">Tuple4</a></li><li><a href="module-eclairjs_ml.Estimator.html">Estimator</a></li><li><a href="module-eclairjs_ml.Model.html">Model</a></li><li><a href="module-eclairjs_ml.Pipeline.html">Pipeline</a></li><li><a href="module-eclairjs_ml.PipelineModel.html">PipelineModel</a></li><li><a href="module-eclairjs_ml.PipelineStage.html">PipelineStage</a></li><li><a href="module-eclairjs_ml.PredictionModel.html">PredictionModel</a></li><li><a href="module-eclairjs_ml.Predictor.html">Predictor</a></li><li><a href="module-eclairjs_ml.Transformer.html">Transformer</a></li><li><a href="module-eclairjs_ml.UnaryTransformer.html">UnaryTransformer</a></li><li><a href="module-eclairjs_ml_attribute.NumericAttribute.html">NumericAttribute</a></li><li><a href="module-eclairjs_ml_classification.ClassificationModel.html">ClassificationModel</a></li><li><a href="module-eclairjs_ml_classification.Classifier.html">Classifier</a></li><li><a href="module-eclairjs_ml_classification.DecisionTreeClassifier.html">DecisionTreeClassifier</a></li><li><a href="module-eclairjs_ml_classification.GBTClassifier.html">GBTClassifier</a></li><li><a href="module-eclairjs_ml_classification.LogisticRegression.html">LogisticRegression</a></li><li><a href="module-eclairjs_ml_classification.LogisticRegressionModel.html">LogisticRegressionModel</a></li><li><a href="module-eclairjs_ml_classification.LogisticRegressionSummary.html">LogisticRegressionSummary</a></li><li><a href="module-eclairjs_ml_classification.LogisticRegressionTrainingSummary.html">LogisticRegressionTrainingSummary</a></li><li><a href="module-eclairjs_ml_classification.MultilayerPerceptronClassificationModel.html">MultilayerPerceptronClassificationModel</a></li><li><a href="module-eclairjs_ml_classification.NaiveBayes.html">NaiveBayes</a></li><li><a href="module-eclairjs_ml_classification.NaiveBayesModel.html">NaiveBayesModel</a></li><li><a href="module-eclairjs_ml_classification.OneVsRestModel.html">OneVsRestModel</a></li><li><a href="module-eclairjs_ml_classification.ProbabilisticClassificationModel.html">ProbabilisticClassificationModel</a></li><li><a href="module-eclairjs_ml_classification.ProbabilisticClassifier.html">ProbabilisticClassifier</a></li><li><a href="module-eclairjs_ml_classification.RandomForestClassificationModel.html">RandomForestClassificationModel</a></li><li><a href="module-eclairjs_ml_classification.RandomForestClassifier.html">RandomForestClassifier</a></li><li><a href="module-eclairjs_ml_clustering.BisectingKMeans.html">BisectingKMeans</a></li><li><a href="module-eclairjs_ml_clustering.BisectingKMeansModel.html">BisectingKMeansModel</a></li><li><a href="module-eclairjs_ml_clustering.GaussianMixture.html">GaussianMixture</a></li><li><a href="module-eclairjs_ml_clustering.GaussianMixtureModel.html">GaussianMixtureModel</a></li><li><a href="module-eclairjs_ml_clustering.GaussianMixtureSummary.html">GaussianMixtureSummary</a></li><li><a href="module-eclairjs_ml_clustering.KMeans.html">KMeans</a></li><li><a href="module-eclairjs_ml_clustering.KMeansModel.html">KMeansModel</a></li><li><a href="module-eclairjs_ml_clustering.LDA.html">LDA</a></li><li><a href="module-eclairjs_ml_clustering.LDAModel.html">LDAModel</a></li><li><a href="module-eclairjs_ml_evaluation.MulticlassClassificationEvaluator.html">MulticlassClassificationEvaluator</a></li><li><a href="module-eclairjs_ml_evaluation.RegressionEvaluator.html">RegressionEvaluator</a></li><li><a href="module-eclairjs_ml_feature.ChiSqSelectorModel.html">ChiSqSelectorModel</a></li><li><a href="module-eclairjs_ml_feature.ElementwiseProduct.html">ElementwiseProduct</a></li><li><a href="module-eclairjs_ml_feature.IDFModel.html">IDFModel</a></li><li><a href="module-eclairjs_ml_feature.IndexToString.html">IndexToString</a></li><li><a href="module-eclairjs_ml_feature.MinMaxScaler.html">MinMaxScaler</a></li><li><a href="module-eclairjs_ml_feature.MinMaxScalerModel.html">MinMaxScalerModel</a></li><li><a href="module-eclairjs_ml_feature.NGram.html">NGram</a></li><li><a href="module-eclairjs_ml_feature.Normalizer.html">Normalizer</a></li><li><a href="module-eclairjs_ml_feature.OneHotEncoder.html">OneHotEncoder</a></li><li><a href="module-eclairjs_ml_feature.PCA.html">PCA</a></li><li><a href="module-eclairjs_ml_feature.PCAModel.html">PCAModel</a></li><li><a href="module-eclairjs_ml_feature.PolynomialExpansion.html">PolynomialExpansion</a></li><li><a href="module-eclairjs_ml_feature.QuantileDiscretizer.html">QuantileDiscretizer</a></li><li><a href="module-eclairjs_ml_feature.RFormulaModel.html">RFormulaModel</a></li><li><a href="module-eclairjs_ml_feature.StandardScalerModel.html">StandardScalerModel</a></li><li><a href="module-eclairjs_ml_feature.StringIndexer.html">StringIndexer</a></li><li><a href="module-eclairjs_ml_feature.StringIndexerModel.html">StringIndexerModel</a></li><li><a href="module-eclairjs_ml_feature.VectorIndexer.html">VectorIndexer</a></li><li><a href="module-eclairjs_ml_feature.VectorIndexerModel.html">VectorIndexerModel</a></li><li><a href="module-eclairjs_ml_feature.Word2VecModel.html">Word2VecModel</a></li><li><a href="module-eclairjs_ml_param.BooleanParam.html">BooleanParam</a></li><li><a href="module-eclairjs_ml_param.DoubleParam.html">DoubleParam</a></li><li><a href="module-eclairjs_ml_param.IntParam.html">IntParam</a></li><li><a href="module-eclairjs_ml_param.Param.html">Param</a></li><li><a href="module-eclairjs_ml_param.ParamMap.html">ParamMap</a></li><li><a href="module-eclairjs_ml_param.ParamPair.html">ParamPair</a></li><li><a href="module-eclairjs_ml_recommendation.ALSModel.html">ALSModel</a></li><li><a href="module-eclairjs_ml_regression.AFTSurvivalRegressionModel.html">AFTSurvivalRegressionModel</a></li><li><a href="module-eclairjs_ml_regression.DecisionTreeRegressionModel.html">DecisionTreeRegressionModel</a></li><li><a href="module-eclairjs_ml_regression.DecisionTreeRegressor.html">DecisionTreeRegressor</a></li><li><a href="module-eclairjs_ml_regression.GBTRegressionModel.html">GBTRegressionModel</a></li><li><a href="module-eclairjs_ml_regression.GBTRegressor.html">GBTRegressor</a></li><li><a href="module-eclairjs_ml_regression.GeneralizedLinearRegression.html">GeneralizedLinearRegression</a></li><li><a href="module-eclairjs_ml_regression.GeneralizedLinearRegressionModel.html">GeneralizedLinearRegressionModel</a></li><li><a href="module-eclairjs_ml_regression.GeneralizedLinearRegressionSummary.html">GeneralizedLinearRegressionSummary</a></li><li><a href="module-eclairjs_ml_regression.GeneralizedLinearRegressionTrainingSummary.html">GeneralizedLinearRegressionTrainingSummary</a></li><li><a href="module-eclairjs_ml_regression.LinearRegression.html">LinearRegression</a></li><li><a href="module-eclairjs_ml_regression.LinearRegressionModel.html">LinearRegressionModel</a></li><li><a href="module-eclairjs_ml_regression.LinearRegressionSummary.html">LinearRegressionSummary</a></li><li><a href="module-eclairjs_ml_regression.LinearRegressionTrainingSummary.html">LinearRegressionTrainingSummary</a></li><li><a href="module-eclairjs_ml_regression.RandomForestRegressionModel.html">RandomForestRegressionModel</a></li><li><a href="module-eclairjs_ml_regression.RandomForestRegressor.html">RandomForestRegressor</a></li><li><a href="module-eclairjs_ml_regression.RegressionModel.html">RegressionModel</a></li><li><a href="module-eclairjs_ml_tuning.CrossValidatorModel.html">CrossValidatorModel</a></li><li><a href="module-eclairjs_ml_tuning.ParamGridBuilder.html">ParamGridBuilder</a></li><li><a href="module-eclairjs_ml_tuning.TrainValidationSplit.html">TrainValidationSplit</a></li><li><a href="module-eclairjs_ml_tuning.TrainValidationSplitModel.html">TrainValidationSplitModel</a></li><li><a href="module-eclairjs_ml_util.MLReadable.html">MLReadable</a></li><li><a href="module-eclairjs_ml_util.MLWritable.html">MLWritable</a></li><li><a href="module-eclairjs_mllib.MLUtils.html">MLUtils</a></li><li><a href="module-eclairjs_mllib_classification.LogisticRegressionModel.html">LogisticRegressionModel</a></li><li><a href="module-eclairjs_mllib_classification.LogisticRegressionWithLBFGS.html">LogisticRegressionWithLBFGS</a></li><li><a href="module-eclairjs_mllib_classification.LogisticRegressionWithSGD.html">LogisticRegressionWithSGD</a></li><li><a href="module-eclairjs_mllib_classification.NaiveBayes.html">NaiveBayes</a></li><li><a href="module-eclairjs_mllib_classification.NaiveBayesModel.html">NaiveBayesModel</a></li><li><a href="module-eclairjs_mllib_classification.SVMModel.html">SVMModel</a></li><li><a href="module-eclairjs_mllib_classification.SVMWithSGD.html">SVMWithSGD</a></li><li><a href="module-eclairjs_mllib_clustering.BisectingKMeans.html">BisectingKMeans</a></li><li><a href="module-eclairjs_mllib_clustering.BisectingKMeansModel.html">BisectingKMeansModel</a></li><li><a href="module-eclairjs_mllib_clustering.KMeans.html">KMeans</a></li><li><a href="module-eclairjs_mllib_clustering.KMeansModel.html">KMeansModel</a></li><li><a href="module-eclairjs_mllib_clustering.LDA.html">LDA</a></li><li><a href="module-eclairjs_mllib_clustering.LDAModel.html">LDAModel</a></li><li><a href="module-eclairjs_mllib_clustering.PowerIterationClustering.html">PowerIterationClustering</a></li><li><a href="module-eclairjs_mllib_clustering.PowerIterationClusteringModel.html">PowerIterationClusteringModel</a></li><li><a href="module-eclairjs_mllib_evaluation.BinaryClassificationMetrics.html">BinaryClassificationMetrics</a></li><li><a href="module-eclairjs_mllib_evaluation.MulticlassMetrics.html">MulticlassMetrics</a></li><li><a href="module-eclairjs_mllib_evaluation.RankingMetrics.html">RankingMetrics</a></li><li><a href="module-eclairjs_mllib_evaluation.RegressionMetrics.html">RegressionMetrics</a></li><li><a href="module-eclairjs_mllib_feature.Word2Vec.html">Word2Vec</a></li><li><a href="module-eclairjs_mllib_feature.Word2VecModel.html">Word2VecModel</a></li><li><a href="module-eclairjs_mllib_fpm.AssociationRules.html">AssociationRules</a></li><li><a href="module-eclairjs_mllib_fpm.FPGrowth.html">FPGrowth</a></li><li><a href="module-eclairjs_mllib_fpm.FPGrowthModel.html">FPGrowthModel</a></li><li><a href="module-eclairjs_mllib_fpm.PrefixSpan.html">PrefixSpan</a></li><li><a href="module-eclairjs_mllib_fpm.PrefixSpanModel.html">PrefixSpanModel</a></li><li><a href="module-eclairjs_mllib_linalg.DenseVector.html">DenseVector</a></li><li><a href="module-eclairjs_mllib_linalg.Matrix.html">Matrix</a></li><li><a href="module-eclairjs_mllib_linalg.SingularValueDecomposition.html">SingularValueDecomposition</a></li><li><a href="module-eclairjs_mllib_linalg.Vector.html">Vector</a></li><li><a href="module-eclairjs_mllib_linalg.Vectors.html">Vectors</a></li><li><a href="module-eclairjs_mllib_linalg_distributed.RowMatrix.html">RowMatrix</a></li><li><a href="module-eclairjs_mllib_optimization.LBFGS.html">LBFGS</a></li><li><a href="module-eclairjs_mllib_optimization.LogisticGradient.html">LogisticGradient</a></li><li><a href="module-eclairjs_mllib_optimization.SquaredL2Updater.html">SquaredL2Updater</a></li><li><a href="module-eclairjs_mllib_random.RandomRDDs.html">RandomRDDs</a></li><li><a href="module-eclairjs_mllib_recommendation.ALS.html">ALS</a></li><li><a href="module-eclairjs_mllib_recommendation.MatrixFactorizationModel.html">MatrixFactorizationModel</a></li><li><a href="module-eclairjs_mllib_recommendation.Rating.html">Rating</a></li><li><a href="module-eclairjs_mllib_regression.LabeledPoint.html">LabeledPoint</a></li><li><a href="module-eclairjs_mllib_regression.LinearRegressionModel.html">LinearRegressionModel</a></li><li><a href="module-eclairjs_mllib_regression.LinearRegressionWithSGD.html">LinearRegressionWithSGD</a></li><li><a href="module-eclairjs_mllib_tree.DecisionTree.html">DecisionTree</a></li><li><a href="module-eclairjs_mllib_tree.GradientBoostedTrees.html">GradientBoostedTrees</a></li><li><a href="module-eclairjs_mllib_tree.RandomForest.html">RandomForest</a></li><li><a href="module-eclairjs_mllib_tree_configuration.BoostingStrategy.html">BoostingStrategy</a></li><li><a href="module-eclairjs_mllib_tree_configuration.Strategy.html">Strategy</a></li><li><a href="module-eclairjs_mllib_tree_loss.Loss.html">Loss</a></li><li><a href="module-eclairjs_mllib_tree_model.DecisionTreeModel.html">DecisionTreeModel</a></li><li><a href="module-eclairjs_mllib_tree_model.GradientBoostedTreesModel.html">GradientBoostedTreesModel</a></li><li><a href="module-eclairjs_mllib_tree_model.RandomForestModel.html">RandomForestModel</a></li><li><a href="module-eclairjs_rdd.FloatRDD.html">FloatRDD</a></li><li><a href="module-eclairjs_rdd.PairRDD.html">PairRDD</a></li><li><a href="module-eclairjs_rdd.RDD.html">RDD</a></li><li><a href="module-eclairjs_sql.Column.html">Column</a></li><li><a href="module-eclairjs_sql.DataFrame.html">DataFrame</a></li><li><a href="module-eclairjs_sql.DataFrameNaFunctions.html">DataFrameNaFunctions</a></li><li><a href="module-eclairjs_sql.DataFrameReader.html">DataFrameReader</a></li><li><a href="module-eclairjs_sql.DataFrameStatFunctions.html">DataFrameStatFunctions</a></li><li><a href="module-eclairjs_sql.DataFrameWriter.html">DataFrameWriter</a></li><li><a href="module-eclairjs_sql.Encoder.html">Encoder</a></li><li><a href="module-eclairjs_sql.Encoders.html">Encoders</a></li><li><a href="module-eclairjs_sql.functions.html">functions</a></li><li><a href="module-eclairjs_sql.GroupedData.html">GroupedData</a></li><li><a href="module-eclairjs_sql.RelationalGroupedDataset.html">RelationalGroupedDataset</a></li><li><a href="module-eclairjs_sql.Row.html">Row</a></li><li><a href="module-eclairjs_sql.RowFactory.html">RowFactory</a></li><li><a href="module-eclairjs_sql.SparkSession.html">SparkSession</a></li><li><a href="module-eclairjs_sql.SQLContext.html">SQLContext</a></li><li><a href="module-eclairjs_sql.SQLContextQueryExecution.html">SQLContextQueryExecution</a></li><li><a href="module-eclairjs_sql.SqlDate.html">SqlDate</a></li><li><a href="module-eclairjs_sql.SqlTimestamp.html">SqlTimestamp</a></li><li><a href="module-eclairjs_sql_streaming.DataStreamReader.html">DataStreamReader</a></li><li><a href="module-eclairjs_sql_streaming.DataStreamWriter.html">DataStreamWriter</a></li><li><a href="module-eclairjs_sql_streaming.SinkStatus.html">SinkStatus</a></li><li><a href="module-eclairjs_sql_streaming.SourceStatus.html">SourceStatus</a></li><li><a href="module-eclairjs_sql_streaming.StreamingQuery.html">StreamingQuery</a></li><li><a href="module-eclairjs_sql_streaming.StreamingQueryInfo.html">StreamingQueryInfo</a></li><li><a href="module-eclairjs_sql_streaming.StreamingQueryListener.html">StreamingQueryListener</a></li><li><a href="module-eclairjs_sql_streaming.StreamingQueryManager.html">StreamingQueryManager</a></li><li><a href="module-eclairjs_sql_types.DataTypes.html">DataTypes</a></li><li><a href="module-eclairjs_sql_types.Metadata.html">Metadata</a></li><li><a href="module-eclairjs_sql_types.StructField.html">StructField</a></li><li><a href="module-eclairjs_sql_types.StructType.html">StructType</a></li><li><a href="module-eclairjs_storage.StorageLevel.html">StorageLevel</a></li><li><a href="module-eclairjs_streaming.Duration.html">Duration</a></li><li><a href="module-eclairjs_streaming.StreamingContext.html">StreamingContext</a></li><li><a href="module-eclairjs_streaming_dstream.DStream.html">DStream</a></li><li><a href="module-eclairjs_streaming_dstream.PairDStream.html">PairDStream</a></li><li><a href="module-eclairjs_streaming_kafka.KafkaUtils.html">KafkaUtils</a></li><li><a href="module-eclairjs_streaming_twitter.TwitterAuthorization.html">TwitterAuthorization</a></li><li><a href="module-eclairjs_streaming_twitter.TwitterUtils.html">TwitterUtils</a></li><li><a href="ReceiverInputDStream.html">ReceiverInputDStream</a></li></ul><h3>Global</h3><ul><li><a href="global.html#handleArguments">handleArguments</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.5.0-dev</a> on Thu Oct 27 2016 11:28:59 GMT-0400 (EDT)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>

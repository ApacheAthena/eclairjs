<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: streaming/dstream/PairDStream.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: streaming/dstream/PairDStream.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/*
 * Copyright 2016 IBM Corp.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


/**
 * @constructor
 * @classdec Represents a Discretized Stream (DStream), the basic abstraction in Spark Streaming,
 * is a continuous sequence of RDDs (of the same type) representing a continuous stream of data.
 * @param {object} jDStream
  */
var PairDStream = function(jPairDStream) {
	var jvmObj = jPairDStream;
	this.logger = Logger.getLogger("streaming.dtream.PairDStream_js");
	JavaWrapper.call(this, jvmObj);
};

PairDStream.prototype = Object.create(DStream.prototype);

PairDStream.prototype.constructor = PairDStream;



/**
 * @param {func} f
 * @returns {PairDStream}
 */
PairDStream.prototype.filter = function(f,bindArgs) {
 var fn = Utils.createLambdaFunction(f,org.eclairjs.nashorn.JSFunction, bindArgs);
  var javaObject =  this.getJavaObject().filter(fn);
  return Utils.javaToJs(javaObject);
};


/**
 * @returns {PairDStream}
 */
PairDStream.prototype.cache = function() {
  var javaObject =  this.getJavaObject().cache();
  return Utils.javaToJs(javaObject);
};


/**
 * @param {StorageLevel} [storageLevel]
 * @returns {PairDStream}
 */
PairDStream.prototype.persist = function(storageLevel) {
  var storageLevel_uw = Utils.unwrapObject(storageLevel);

  if (arguments[0]) {
  var javaObject =  this.getJavaObject().persist(storageLevel_uw);
  return Utils.javaToJs(javaObject);
  } else {
  var javaObject =  this.getJavaObject().persist();
  return Utils.javaToJs(javaObject);
  }
};


/**
 * Return a new DStream with an increased or decreased level of parallelism. Each RDD in the
 * returned DStream has exactly numPartitions partitions.
 * @param {number} numPartitions
 * @returns {PairDStream}
 */
PairDStream.prototype.repartition = function(numPartitions) {
  var javaObject =  this.getJavaObject().repartition(numPartitions);
  return Utils.javaToJs(javaObject);
};


/**
 * @param {Time} validTime
 * @returns {JavaPairRDD}
 */
PairDStream.prototype.compute = function(validTime) {
  var validTime_uw = Utils.unwrapObject(validTime);
  var javaObject =  this.getJavaObject().compute(validTime_uw);
  return new JavaPairRDD(javaObject);
};


/**
 * Return a new DStream which is computed based on windowed batches of this DStream.
 * @param {Duration} windowDuration  duration (i.e., width) of the window;
 *                   must be a multiple of this DStream's interval
 * @param {Duration} [slideDuration]   sliding interval of the window (i.e., the interval after which
 *                   the new DStream will generate RDDs); must be a multiple of this
 *                   DStream's interval
 * @returns {PairDStream}
 */
PairDStream.prototype.window = function(windowDuration,slideDuration) {
  var windowDuration_uw = Utils.unwrapObject(windowDuration);
  var slideDuration_uw = Utils.unwrapObject(slideDuration);

  if (arguments[1]) {
  var javaObject =  this.getJavaObject().window(windowDuration_uw,slideDuration_uw);
  return Utils.javaToJs(javaObject);
  } else {
  var javaObject =  this.getJavaObject().window(windowDuration_uw);
  return Utils.javaToJs(javaObject);
  }
};


/**
 * Return a new DStream by unifying data of another DStream with this DStream.
 * @param {PairDStream} that  Another DStream having the same interval (i.e., slideDuration) as this DStream.
 * @returns {PairDStream}
 */
PairDStream.prototype.union = function(that) {
  var that_uw = Utils.unwrapObject(that);
  var javaObject =  this.getJavaObject().union(that_uw);
  return Utils.javaToJs(javaObject);
};


/**
 * Return a new DStream by applying `groupByKey` to each RDD. Hash partitioning is used to
 * generate the RDDs with Spark's default number of partitions.
 * @returns {PairDStream}
 */
PairDStream.prototype.groupByKey = function() {
  var javaObject =  this.getJavaObject().groupByKey();
  return Utils.javaToJs(javaObject);
};



/**
 * Combine elements of each key in DStream's RDDs using custom function. This is similar to the
 * combineByKey for RDDs. Please refer to combineByKey in
 * org.apache.spark.rdd.PairRDDFunctions for more information.
 * @param {func} createCombiner
 * @param {func} mergeValue
 * @param {func} mergeCombiners
 * @param {Partitioner} partitioner
 * @param {boolean} [mapSideCombine]
 * @returns {PairDStream}
 */
PairDStream.prototype.combineByKey = function(createCombiner,mergeValue,mergeCombiners,partitioner,mapSideCombine,bindArgs) {
 var fn = Utils.createLambdaFunction(createCombiner,org.eclairjs.nashorn.JSFunction, bindArgs);
 var fn2 = Utils.createLambdaFunction(mergeValue,org.eclairjs.nashorn.JSFunction2, bindArgs);
 var fn3 = Utils.createLambdaFunction(mergeCombiners,org.eclairjs.nashorn.JSFunction2, bindArgs);
  var partitioner_uw = Utils.unwrapObject(partitioner);

  if (arguments[4]) {
  var javaObject =  this.getJavaObject().combineByKey(fn,fn2,fn3,partitioner_uw,mapSideCombine);
  return Utils.javaToJs(javaObject);
  } else {
  var javaObject =  this.getJavaObject().combineByKey(fn,fn2,fn3,partitioner_uw);
  return Utils.javaToJs(javaObject);
  }
};
/**
 * Return a new DStream by applying `reduceByKey` to each RDD. The values for each key are
 * merged using the associative reduce function. Hash partitioning is used to generate the RDDs
 * with Spark's default number of partitions.
 * @param {func} func
 * @returns {PairDStream}
 */
PairDStream.prototype.reduceByKey = function(func,bindArgs) {
      var fn = Utils.createLambdaFunction(func, org.eclairjs.nashorn.JSFunction2, bindArgs);
  var javaObject =  this.getJavaObject().reduceByKey(fn);
  return Utils.javaToJs(javaObject);
};



/**
 * Create a new DStream by applying `reduceByKey` over a sliding window on `this` DStream.
 * Similar to `DStream.reduceByKey()`, but applies it over a sliding window. The new DStream
 * generates RDDs with the same interval as this DStream. Hash partitioning is used to generate
 * the RDDs with Spark's default number of partitions.
 * @param {func} reduceFunc  associative reduce function
 * @param {Duration} windowDuration  width of the window; must be a multiple of this DStream's
 *                       batching interval
 * @returns {PairDStream}
 */
PairDStream.prototype.reduceByKeyAndWindow = function(reduceFunc,windowDuration,bindArgs) {
 var fn = Utils.createLambdaFunction(reduceFunc,org.eclairjs.nashorn.JSFunction2, bindArgs);
  var windowDuration_uw = Utils.unwrapObject(windowDuration);
  var javaObject =  this.getJavaObject().reduceByKeyAndWindow(fn,windowDuration_uw);
  return Utils.javaToJs(javaObject);
};

/**
 * Return a new DStream by applying a map function to the value of each key-value pairs in
 * 'this' DStream without changing the key.
 * @param {func} f
 * @returns {PairDStream}
 */
PairDStream.prototype.mapValues = function(f,bindArgs) {
 var fn = Utils.createLambdaFunction(f,org.eclairjs.nashorn.JSFunction, bindArgs);
  var javaObject =  this.getJavaObject().mapValues(fn);
  return Utils.javaToJs(javaObject);
};


/**
 * Return a new DStream by applying a flatmap function to the value of each key-value pairs in
 * 'this' DStream without changing the key.
 * @param {func} f
 * @returns {PairDStream}
 */
PairDStream.prototype.flatMapValues = function(f,bindArgs) {
 var fn = Utils.createLambdaFunction(f,org.eclairjs.nashorn.JSFunction, bindArgs);
  var javaObject =  this.getJavaObject().flatMapValues(fn);
  return Utils.javaToJs(javaObject);
};
</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Classes</h3><ul><li><a href="Accumulable.html">Accumulable</a></li><li><a href="AccumulableParam.html">AccumulableParam</a></li><li><a href="Accumulator.html">Accumulator</a></li><li><a href="ALS.html">ALS</a></li><li><a href="ArrayType.html">ArrayType</a></li><li><a href="AssociationRules.html">AssociationRules</a></li><li><a href="BinaryClassificationMetrics.html">BinaryClassificationMetrics</a></li><li><a href="BinaryType.html">BinaryType</a></li><li><a href="BisectingKMeans.html">BisectingKMeans</a></li><li><a href="BisectingKMeansModel.html">BisectingKMeansModel</a></li><li><a href="BooleanType.html">BooleanType</a></li><li><a href="BoostingStrategy.html">BoostingStrategy</a></li><li><a href="CalendarIntervalType.html">CalendarIntervalType</a></li><li><a href="Column.html">Column</a></li><li><a href="DataFrame.html">DataFrame</a></li><li><a href="DataFrameNaFunctions.html">DataFrameNaFunctions</a></li><li><a href="DataFrameReader.html">DataFrameReader</a></li><li><a href="DataFrameStatFunctions.html">DataFrameStatFunctions</a></li><li><a href="DataFrameWriter.html">DataFrameWriter</a></li><li><a href="DataType.html">DataType</a></li><li><a href="DataTypes.html">DataTypes</a></li><li><a href="DateType.html">DateType</a></li><li><a href="DecisionTree.html">DecisionTree</a></li><li><a href="DecisionTreeModel.html">DecisionTreeModel</a></li><li><a href="DenseMatrix.html">DenseMatrix</a></li><li><a href="DenseVector.html">DenseVector</a></li><li><a href="DistributedLDAModel.html">DistributedLDAModel</a></li><li><a href="DistributedMatrix.html">DistributedMatrix</a></li><li><a href="DoubleType.html">DoubleType</a></li><li><a href="DStream.html">DStream</a></li><li><a href="Duration.html">Duration</a></li><li><a href="FloatAccumulatorParam.html">FloatAccumulatorParam</a></li><li><a href="FloatRDD.html">FloatRDD</a></li><li><a href="FloatType.html">FloatType</a></li><li><a href="FPGrowth.html">FPGrowth</a></li><li><a href="FPGrowthModel.html">FPGrowthModel</a></li><li><a href="FreqItemset.html">FreqItemset</a></li><li><a href="functions.html">functions</a></li><li><a href="FutureAction.html">FutureAction</a></li><li><a href="GeneralizedLinearModel.html">GeneralizedLinearModel</a></li><li><a href="Gradient.html">Gradient</a></li><li><a href="GradientBoostedTrees.html">GradientBoostedTrees</a></li><li><a href="GradientBoostedTreesModel.html">GradientBoostedTreesModel</a></li><li><a href="GroupedData.html">GroupedData</a></li><li><a href="HashPartitioner.html">HashPartitioner</a></li><li><a href="IntAccumulatorParam.html">IntAccumulatorParam</a></li><li><a href="IntegerType.html">IntegerType</a></li><li><a href="IsotonicRegression.html">IsotonicRegression</a></li><li><a href="IsotonicRegressionModel.html">IsotonicRegressionModel</a></li><li><a href="KMeans.html">KMeans</a></li><li><a href="KMeansModel.html">KMeansModel</a></li><li><a href="LabeledPoint.html">LabeledPoint</a></li><li><a href="LBFGS.html">LBFGS</a></li><li><a href="LDA.html">LDA</a></li><li><a href="LDAModel.html">LDAModel</a></li><li><a href="LinearRegressionModel.html">LinearRegressionModel</a></li><li><a href="LinearRegressionWithSGD.html">LinearRegressionWithSGD</a></li><li><a href="List.html">List</a></li><li><a href="LocalLDAModel.html">LocalLDAModel</a></li><li><a href="Logger.html">Logger</a></li><li><a href="LogisticGradient.html">LogisticGradient</a></li><li><a href="LogisticRegressionModel.html">LogisticRegressionModel</a></li><li><a href="LogisticRegressionWithLBFGS.html">LogisticRegressionWithLBFGS</a></li><li><a href="LogisticRegressionWithSGD.html">LogisticRegressionWithSGD</a></li><li><a href="Loss.html">Loss</a></li><li><a href="MapType.html">MapType</a></li><li><a href="Matrix.html">Matrix</a></li><li><a href="MatrixFactorizationModel.html">MatrixFactorizationModel</a></li><li><a href="Metadata.html">Metadata</a></li><li><a href="MLWord2Vec.html">MLWord2Vec</a></li><li><a href="MLWord2VecModel.html">MLWord2VecModel</a></li><li><a href="MulticlassMetrics.html">MulticlassMetrics</a></li><li><a href="MultilabelMetrics.html">MultilabelMetrics</a></li><li><a href="NaiveBayes.html">NaiveBayes</a></li><li><a href="NaiveBayesModel.html">NaiveBayesModel</a></li><li><a href="NullType.html">NullType</a></li><li><a href="NumericType.html">NumericType</a></li><li><a href="PairDStream.html">PairDStream</a></li><li><a href="PairRDD.html">PairRDD</a></li><li><a href="PartialResult.html">PartialResult</a></li><li><a href="Partitioner.html">Partitioner</a></li><li><a href="PowerIterationClustering.html">PowerIterationClustering</a></li><li><a href="PowerIterationClusteringAssignment.html">PowerIterationClusteringAssignment</a></li><li><a href="PowerIterationClusteringModel.html">PowerIterationClusteringModel</a></li><li><a href="RandomForest.html">RandomForest</a></li><li><a href="RandomForestModel.html">RandomForestModel</a></li><li><a href="RangePartitioner.html">RangePartitioner</a></li><li><a href="RankingMetrics.html">RankingMetrics</a></li><li><a href="Rating.html">Rating</a></li><li><a href="RDD.html">RDD</a></li><li><a href="RegressionMetrics.html">RegressionMetrics</a></li><li><a href="Row.html">Row</a></li><li><a href="RowFactory.html">RowFactory</a></li><li><a href="RowMatrix.html">RowMatrix</a></li><li><a href="Rule.html">Rule</a></li><li><a href="SparkConf.html">SparkConf</a></li><li><a href="SparkContext.html">SparkContext</a></li><li><a href="SparkFiles.html">SparkFiles</a></li><li><a href="SparkStatusTracker.html">SparkStatusTracker</a></li><li><a href="SparseMatrix.html">SparseMatrix</a></li><li><a href="SparseVector.html">SparseVector</a></li><li><a href="SQLContext.html">SQLContext</a></li><li><a href="SQLContext.QueryExecution.html">QueryExecution</a></li><li><a href="SQLContext.SparkPlanner.html">SparkPlanner</a></li><li><a href="SQLContext.SQLSession.html">SQLSession</a></li><li><a href="SqlDate.html">SqlDate</a></li><li><a href="SqlTimestamp.html">SqlTimestamp</a></li><li><a href="SquaredL2Updater.html">SquaredL2Updater</a></li><li><a href="StorageLevel.html">StorageLevel</a></li><li><a href="Strategy.html">Strategy</a></li><li><a href="StreamingContext.html">StreamingContext</a></li><li><a href="StringType.html">StringType</a></li><li><a href="StructField.html">StructField</a></li><li><a href="StructType.html">StructType</a></li><li><a href="Time.html">Time</a></li><li><a href="TimestampType.html">TimestampType</a></li><li><a href="Tuple.html">Tuple</a></li><li><a href="Updater.html">Updater</a></li><li><a href="Vector.html">Vector</a></li><li><a href="Vectors.html">Vectors</a></li><li><a href="VectorUDT.html">VectorUDT</a></li><li><a href="Word2Vec.html">Word2Vec</a></li><li><a href="Word2VecModel.html">Word2VecModel</a></li></ul><h3>Interfaces</h3><ul><li><a href="ClassificationModel.html">ClassificationModel</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.3.2</a> on Mon Mar 21 2016 16:57:48 GMT-0400 (EDT)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
